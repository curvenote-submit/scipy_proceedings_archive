@Book{hume48,
  author =  "David Hume",
  year =    "1748",
  title =   "An enquiry concerning human understanding",
  address =     "Indianapolis, IN",
  publisher =   "Hackett",
  doi = "10.1017/CBO9780511808432",
}

@article{kjaerulff2008bayesian,
  title={Bayesian networks and influence diagrams},
  author={Kjaerulff, Uffe B and Madsen, Anders L},
  journal={Springer Science+ Business Media},
  volume={200},
  pages={114},
  year={2008},
  publisher={Springer}
}

@incollection{gomez2004real,
  title={Real-world applications of influence diagrams},
  author={G{\'o}mez, Manuel},
  booktitle={Advances in Bayesian networks},
  pages={161--180},
  year={2004},
  publisher={Springer},
  doi = "10.1007/978-3-540-39879-0_9",
}

@article{koller2003multi,
  title={Multi-agent influence diagrams for representing and solving games},
  author={Koller, Daphne and Milch, Brian},
  journal={Games and economic behavior},
  volume={45},
  number={1},
  pages={181--221},
  year={2003},
  publisher={Elsevier},
  doi = "10.1016/s0899-8256(02)00544-4",
}

@article{howard1966information,
  title={Information value theory},
  author={Howard, Ronald A},
  journal={IEEE Transactions on systems science and cybernetics},
  volume={2},
  number={1},
  pages={22--26},
  year={1966},
  publisher={IEEE}
}

@article{shachter1986evaluating,
  title={Evaluating influence diagrams},
  author={Shachter, Ross D},
  journal={Operations research},
  volume={34},
  number={6},
  pages={871--882},
  year={1986},
  publisher={INFORMS}
}

@inproceedings{hammond2021equilibrium,
  title={Equilibrium Refinements for Multi-Agent Influence Diagrams: Theory and Practice},
  author={Hammond, Lewis and Fox, James and Everitt, Tom and Abate, Alessandro and Wooldridge, Michael},
  booktitle={Proceedings of the 20th International Conference on Autonomous Agents and MultiAgent Systems},
  pages={574--582},
  year={2021}
}

@book{pearl2009causality,
  title={Causality},
  author={Pearl, Judea},
  year={2009},
  publisher={Cambridge university press}
}

@inproceedings{everitt2021agent,
  title={Agent incentives: A causal perspective},
  author={Everitt, Tom and Carey, Ryan and Langlois, Eric and Ortega, Pedro and Legg, Shane},
  booktitle={Proceedings of the Thirty-Fifth AAAI Conference on Artificial Intelligence,(AAAI-21). Virtual. Forthcoming},
  year={2021}
}


@inproceedings{ankan2015pgmpy,
author = {Ankan, Ankur and Panda, Abinash},
booktitle = {{P}roceedings of the 14th {P}ython in {S}cience {C}onference},
doi = {10.25080/Majora-7b98e3ed-001},
editor = {Huff, Kathryn and Bergstra, James},
pages = {6--11},
title = {{pgmpy: {P}robabilistic {G}raphical {M}odels using {P}ython}},
year = {2015}
}


@article{carey2020incentives,
  title={The incentives that shape behaviour},
  author={Carey, Ryan and Langlois, Eric and Everitt, Tom and Legg, Shane},
  journal={arXiv preprint arXiv:2001.07118},
  year={2020}
}

@article{everitt2021reward,
  title={Reward tampering problems and solutions in reinforcement learning: A causal influence diagram perspective},
  author={Everitt, Tom and Hutter, Marcus and Kumar, Ramana and Krakovna, Victoria},
  journal={Synthese},
  pages={1--33},
  year={2021},
  publisher={Springer},
  doi = "10.1007/s11229-021-03141-4",
}

@inproceedings{holtman2020towards,
abstract = {While it is still unclear if agents with Artificial General Intelligence ({AGI}) could ever be built, we can already use mathematical models to investigate potential safety systems for these agents. We present work on an {AGI} safety layer that creates a special dedicated input terminal to support the iterative improvement of an AGI agent's utility function. The humans who switched on the agent can use this terminal to close any loopholes that are discovered in the utility function's encoding of agent goals and constraints, to direct the agent towards new goals, or to force the agent to switch itself off.},
address = {Cham},
author = {Holtman, Koen},
booktitle = {Artificial General Intelligence},
doi = {10.1007/978-3-030-52152-3_21},
editor = {Goertzel, Ben and Panov, Aleksandr I and Potapov, Alexey and Yampolskiy, Roman},
isbn = {978-3-030-52152-3},
pages = {205--215},
publisher = {Springer International Publishing},
title = {{Towards {AGI} Agent Safety by Iteratively Improving the Utility Function}},
year = {2020}
}

@inproceedings{everitt2019modeling,
  archiveprefix = {arXiv},
  arxivid = {1906.08663},
  author = {Everitt, Tom and Kumar, Ramana and Krakovna, Victoria and Legg, Shane},
  booktitle = {IJCAI AI Safety Workshop},
  eprint = {1906.08663},
  title = {Modeling {AGI} Safety Frameworks with Causal Influence Diagrams},
  year = {2019},
  abstract = {Proposals for safe AGI systems are typically made at the level of frameworks, specifying how the components of the proposed system should be trained and interact with each other. In this paper, we model and compare the most promising AGI safety frameworks using causal influence diagrams. The diagrams show the optimization objective and causal assumptions of the framework. The unified representation permits easy comparison of frameworks and their assumptions. We hope that the diagrams will serve as an accessible and visual introduction to the main AGI safety frameworks.}
}

@inproceedings{langlois2021rl,
  abstract = {Reinforcement learning in complex environments may require supervision to prevent the agent from attempting dangerous actions. As a result of supervisor intervention, the executed action may differ from the action specified by the policy. How does this affect learning? We present the Modified-Action Markov Decision Process, an extension of the MDP model that allows actions to differ from the policy. We analyze the asymptotic behaviours of common reinforcement learning algorithms in this setting and show that they adapt in different ways: some completely ignore modifications while others go to various lengths in trying to avoid action modifications that decrease reward. By choosing the right algorithm, developers can prevent their agents from learning to circumvent interruptions or constraints, and better control agent responses to other kinds of action modification, like self-damage.},
  archiveprefix = {arXiv},
  arxivid = {2102.07716},
  author = {Langlois, Eric and Everitt, Tom},
  booktitle = {AAAI},
  eprint = {2102.07716},
  title = {How {RL} Agents Behave When Their Actions Are Modified},
  year = {2021}
}

@inproceedings{hal-02911619,
  TITLE = {{aGrUM/pyAgrum : a Toolbox to Build Models and Algorithms for Probabilistic Graphical Models in Python}},
  AUTHOR = {Ducamp, Gaspard and Bonnard, Philippe and De Sainte Marie, Christian and Wuillemin, Pierre-Henri},
  URL = {https://hal.archives-ouvertes.fr/hal-02911619},
  BOOKTITLE = {{10th International Conference on Probabilistic Graphical Models}},
  ADDRESS = {Sk{{\o}}rping, Denmark},
  SERIES = {Proceedings of Machine Learning Research},
  VOLUME = {138},
  PAGES = {173-184},
  YEAR = {2020},
  KEYWORDS = {Bayesian Networks ; Probabilistic Graphical Models ; c++ ; python},
  PDF = {https://hal.archives-ouvertes.fr/hal-02911619/file/paper39.pdf},
  HAL_ID = {hal-02911619},
  HAL_VERSION = {v1},
}

@misc{pySMILE,
  author = {BayesFusionLLC},
  title = {{SMILE: Structural Modeling, Inference, and Learning Engine}},
  url = {https://www.bayesfusion.com/smile},
  urldate = {2021-06-16}
}

@inproceedings{Kusner2017,
abstract = {Machine learning can impact people with legal or ethical consequences when it is used to automate decisions in areas such as insurance, lending, hiring, and predictive policing. In many of these scenarios, previous decisions have been made that are unfairly biased against certain subpopulations, for example those of a particular race, gender, or sexual orientation. Since this past data may be biased, machine learning predictors must account for this to avoid perpetuating or creating discriminatory practices. In this paper, we develop a framework for modeling fairness using tools from causal inference. Our definition of counterfactual fairness captures the intuition that a decision is fair towards an individual if it the same in (a) the actual world and (b) a counterfactual world where the individual belonged to a different demographic group. We demonstrate our framework on a real-world problem of fair prediction of success in law school.},
archivePrefix = {arXiv},
arxivId = {1703.06856},
author = {Kusner, Matt and Loftus, Joshua and Russell, Chris and Silva, Ricardo},
booktitle = {Advances in Neural Information Processing Systems},
eprint = {1703.06856},
issn = {10495258},
mendeley-groups = {Causality,AI},
pages = {4067--4077},
publisher = {Neural information processing systems foundation},
title = {{Counterfactual fairness}},
url = {http://arxiv.org/abs/1703.06856},
volume = {2017-Decem},
year = {2017}
}



@article{causalgames,
  title={Causality in Games},
  author={Hammond, Lewis and Fox, James and Everitt, Tom and Carey, Ryan and Abate, Alessandro and Wooldridge, Michael},
  journal={Forthcoming},
}

@article{multidecision,
  title={Techniques For Analysing Multi-decision Influence
Diagrams},
  author={van Merwijk, Chris and Carey, Ryan and Everitt, Tom},
  journal={Forthcoming},
}


@article{howard2005influence,
  title={Influence diagrams},
  author={Howard, Ronald A and Matheson, James E},
  journal={Decision Analysis},
  volume={2},
  number={3},
  pages={127--143},
  year={2005},
  publisher={INFORMS},
  doi = "10.1287/deca.1050.0020"
}


@article{borgonovo2016sensitivity,
  title={Sensitivity analysis: a review of recent advances},
  author={Borgonovo, Emanuele and Plischke, Elmar},
  journal={European Journal of Operational Research},
  volume={248},
  number={3},
  pages={869--887},
  year={2016},
  publisher={Elsevier},
  doi = "10.1016/j.ejor.2015.06.032"
}

@techreport{miller1976development,
  title={Development of automated aids for decision analysis},
  author={Miller III, Allen C and Merkhofer, Miley W and Howard, Ronald A and Matheson, James E and Rice, Thomas R},
  year={1976},
  institution={STANFORD RESEARCH INST MENLO PARK CA},
  doi = "10.21236/ada026379",
}

@inproceedings{pfeffer2007reasoning,
title = "On the reasoning patterns of agents in games",
abstract = "What reasoning patterns do agents use to choose their actions in games? This paper studies this question in the context of Multi-Agent Influence Diagrams (MAIDs). It defines several kinds of reasoning patterns, and associates each with a pattern of paths in a MAID. We asks the question, what reasoning patterns have to hold in order for an agent to care about its decision? The answer depends on what strategies are considered for other agents' decisions. We introduce a new solution concept, called well-distinguishing (WD) strategies, that captures strategies in which all the distinctions an agent makes really make a difference. We show that when agents are playing WD strategies, all situations in which an agent cares about its decision can be captured by four reasoning patterns. We furthermore show that when one of these four patterns holds, there are some MAID parameter values such that the agent actually does care about its decision.",
author = "Avi Pfeffer and Yakov Gal",
year = "2007",
language = "English",
isbn = "978-1-57735-323-2",
pages = "102--109",
booktitle = "Proceedings of the 22nd national conference on Artificial intelligence - Volume 1",
publisher = "AAAI Press",
note = "22nd national conference on Artificial intelligence, AAAI-07 ; Conference date: 22-07-2007 Through 26-07-2007",
url = "https://www.aaai.org/Conferences/AAAI/aaai07.php",
}

@InProceedings{hagberg2008exploring,
  author =       {Aric A. Hagberg and Daniel A. Schult and Pieter J. Swart},
  title =        {Exploring Network Structure, Dynamics, and Function using {N}etwork{X}},
  booktitle =   {Proceedings of the 7th Python in Science Conference},
  pages =     {11 - 15},
  address = {Pasadena, CA USA},
  year =      {2008},
  editor =    {Ga\"el Varoquaux and Travis Vaught and Jarrod Millman},
}

@article{nash1950equilibrium,
  title={Equilibrium points in n-person games},
  author={Nash, John F and others},
  journal={Proceedings of the national academy of sciences},
  volume={36},
  number={1},
  pages={48--49},
  year={1950},
  publisher={USA},
  doi = "10.2307/j.ctv173f1fh.6",
}

@article{selten1965spieltheoretische,
  title={Spieltheoretische behandlung eines oligopolmodells mit nachfragetr{\"a}gheit: Teil i: Bestimmung des dynamischen preisgleichgewichts},
  author={Selten, Reinhard},
  journal={Zeitschrift f{\"u}r die gesamte Staatswissenschaft/Journal of Institutional and Theoretical Economics},
  number={H. 2},
  pages={301--324},
  year={1965},
  publisher={JSTOR}
}

@inproceedings{cohen2020asymptotically,
  title={Asymptotically unambitious artificial general intelligence},
  author={Cohen, Michael and Vellambi, Badri and Hutter, Marcus},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={03},
  pages={2467--2476},
  year={2020},
  doi = "10.1609/aaai.v34i03.5628",
}

@article{hunter2007matplotlib,
  title={Matplotlib: A 2{D} graphics environment},
  author={Hunter, John D},
  journal={IEEE Annals of the History of Computing},
  volume={9},
  number={03},
  pages={90--95},
  year={2007},
  publisher={IEEE Computer Society},
  doi = "10.1109/MCSE.2007.55"
}

@Article{harris2020array,
 title={Array programming with {NumPy}},
 author = {Charles R. Harris and K. Jarrod Millman and St{\'{e}}fan J.
          van der Walt and Ralf Gommers and Pauli Virtanen and David
          Cournapeau and Eric Wieser and Julian Taylor and Sebastian
          Berg and Nathaniel J. Smith and Robert Kern and Matti Picus
          and Stephan Hoyer and Marten H. van Kerkwijk and Matthew
          Brett and Allan Haldane and Jaime Fern{\'{a}}ndez del
          R{\'{i}}o and Mark Wiebe and Pearu Peterson and Pierre
          G{\'{e}}rard-Marchant and Kevin Sheppard and Tyler Reddy and
          Warren Weckesser and Hameer Abbasi and Christoph Gohlke and
          Travis E. Oliphant},
 year={2020},
 journal = {Nature},
 volume = {585},
 number = {7825},
 pages = {357--362},
 publisher = {Springer Science and Business Media {LLC}},
 doi = "10.1038/s41586-020-2649-2"
}





